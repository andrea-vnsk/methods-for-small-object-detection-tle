{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7949b824-0ca0-42c1-aa6e-de0ef6b2025f",
   "metadata": {},
   "source": [
    "# **Single Shot MultiBox Detector** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f186bb3b-5f01-4352-9e1e-08204ec35937",
   "metadata": {},
   "source": [
    "Postup vytvorenia modelu SSD v tomto notebooku je založený na <a href=\"https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/blob/master/Train_TFLite2_Object_Detction_Model.ipynb\">originálnom notebooku.</a> a bol pripravený pre prostredie <a href=\"https://colab.google/\" > Google Colab</a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f53aab-f3c4-47fa-8bc3-ffc69c5ae104",
   "metadata": {},
   "source": [
    "### Príprava prostredia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baa7a18-3fd7-4165-8cd5-754d76a257bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall Cython -y \n",
    "!git clone --depth 1 https://github.com/tensorflow/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f41a7a8-9d8a-4e8b-b2eb-d6afdbebf448",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd models/research/\n",
    "protoc object_detection/protos/*.proto --python_out=."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff62271-64e0-4486-9967-efb1465bd8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "with open('/content/models/research/object_detection/packages/tf2/setup.py') as f:\n",
    "    s = f.read()\n",
    "\n",
    "with open('/content/models/research/setup.py', 'w') as f:\n",
    "    # Set fine_tune_checkpoint path\n",
    "    s = re.sub('tf-models-official>=2.5.1',\n",
    "               'tf-models-official==2.8.0', s)\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09ff366-6d93-4c81-b1d2-9bf1cf5960a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the Object Detection API (NOTE: This block takes about 10 minutes to finish executing)\n",
    "\n",
    "# Need to do a temporary fix with PyYAML because Colab isn't able to install PyYAML v5.4.1\n",
    "!pip install pyyaml==5.3\n",
    "!pip install /content/models/research/\n",
    "\n",
    "# Need to downgrade to TF v2.8.0 due to Colab compatibility bug with TF v2.10 (as of 10/03/22)\n",
    "!pip install tensorflow==2.8.0\n",
    "\n",
    "# Install CUDA version 11.0 (to maintain compatibility with TF v2.8.0)\n",
    "!pip install tensorflow_io==0.23.1\n",
    "!wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-ubuntu1804.pin\n",
    "!mv cuda-ubuntu1804.pin /etc/apt/preferences.d/cuda-repository-pin-600\n",
    "!wget http://developer.download.nvidia.com/compute/cuda/11.0.2/local_installers/cuda-repo-ubuntu1804-11-0-local_11.0.2-450.51.05-1_amd64.deb\n",
    "!dpkg -i cuda-repo-ubuntu1804-11-0-local_11.0.2-450.51.05-1_amd64.deb\n",
    "!apt-key add /var/cuda-repo-ubuntu1804-11-0-local/7fa2af80.pub\n",
    "!apt-get update && sudo apt-get install cuda-toolkit-11-0\n",
    "!export LD_LIBRARY_PATH=/usr/local/cuda-11.0/lib64:$LD_LIBRARY_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd3490f-62d3-4b1f-8680-d31fb2533468",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python /content/models/research/object_detection/builders/model_builder_tf2_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a7b3fa-342e-4703-8f76-4691b9c72d59",
   "metadata": {},
   "source": [
    "### Príprava dát "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab359e9a-bfa4-401d-946a-870e3e04a204",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat <<EOF >> /content/labelmap.txt\n",
    "TLE\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e03cb9-876e-4b0f-80db-d11c7b01f324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data conversion scripts\n",
    "! wget https://raw.githubusercontent.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/master/util_scripts/create_csv.py\n",
    "! wget https://raw.githubusercontent.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/master/util_scripts/create_tfrecord.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bcd577-60d4-4532-9186-32ee1c8c934d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tvorba súborov dát CSV a TFRecord súborov\n",
    "!python3 create_csv.py\n",
    "\n",
    "# Je potrebné mať obrázky v súbore \"images\", ktorá ma podsúbory \"train\" a \"val\", v ktorých sú uložené obrázky a ich XML anotácie\n",
    "!python3 create_tfrecord.py --csv_input=images/train_labels.csv --labelmap=labelmap.txt --image_dir=images/train --output_path=train.tfrecord\n",
    "!python3 create_tfrecord.py --csv_input=images/validation_labels.csv --labelmap=labelmap.txt --image_dir=images/validation --output_path=val.tfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2538ecbc-5530-4d2a-8966-8ceb9c30b62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_record_fname = '/content/train.tfrecord'\n",
    "val_record_fname = '/content/val.tfrecord'\n",
    "label_map_pbtxt_fname = '/content/labelmap.pbtxt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0150accc-bfdd-47cb-aa61-d267d7dc1856",
   "metadata": {},
   "source": [
    "### Nastavenie konfigurácií pre tréning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0271a21-3eb5-4692-9ea2-88c516e6d9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the chosen_model variable to deploy different models available in the TF2 object detection zoo\n",
    "chosen_model = 'ssd-mobilenet-v2-fpnlite-320'\n",
    "\n",
    "MODELS_CONFIG = {\n",
    "    'ssd-mobilenet-v2': {\n",
    "        'model_name': 'ssd_mobilenet_v2_320x320_coco17_tpu-8',\n",
    "        'base_pipeline_file': 'ssd_mobilenet_v2_320x320_coco17_tpu-8.config',\n",
    "        'pretrained_checkpoint': 'ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz',\n",
    "    },\n",
    "    'efficientdet-d0': {\n",
    "        'model_name': 'efficientdet_d0_coco17_tpu-32',\n",
    "        'base_pipeline_file': 'ssd_efficientdet_d0_512x512_coco17_tpu-8.config',\n",
    "        'pretrained_checkpoint': 'efficientdet_d0_coco17_tpu-32.tar.gz',\n",
    "    },\n",
    "    'ssd-mobilenet-v2-fpnlite-320': {\n",
    "        'model_name': 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8',\n",
    "        'base_pipeline_file': 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config',\n",
    "        'pretrained_checkpoint': 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz',\n",
    "    },\n",
    "    # The centernet model isn't working as of 9/10/22\n",
    "    #'centernet-mobilenet-v2': {\n",
    "    #    'model_name': 'centernet_mobilenetv2fpn_512x512_coco17_od',\n",
    "    #    'base_pipeline_file': 'pipeline.config',\n",
    "    #    'pretrained_checkpoint': 'centernet_mobilenetv2fpn_512x512_coco17_od.tar.gz',\n",
    "    #}\n",
    "}\n",
    "\n",
    "model_name = MODELS_CONFIG[chosen_model]['model_name']\n",
    "pretrained_checkpoint = MODELS_CONFIG[chosen_model]['pretrained_checkpoint']\n",
    "base_pipeline_file = MODELS_CONFIG[chosen_model]['base_pipeline_file']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adec0f24-43c1-4f20-8ef2-fc40813bb11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create \"mymodel\" folder for holding pre-trained weights and configuration files\n",
    "%mkdir /content/models/mymodel/\n",
    "%cd /content/models/mymodel/\n",
    "\n",
    "# Download pre-trained model weights\n",
    "import tarfile\n",
    "download_tar = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/' + pretrained_checkpoint\n",
    "!wget {download_tar}\n",
    "tar = tarfile.open(pretrained_checkpoint)\n",
    "tar.extractall()\n",
    "tar.close()\n",
    "\n",
    "# Download training configuration file for model\n",
    "download_config = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/' + base_pipeline_file\n",
    "!wget {download_config}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfb5d5f-1827-4318-93d4-659ef2dc9717",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 40000\n",
    "\n",
    "if chosen_model == 'efficientdet-d0':\n",
    "      batch_size = 4\n",
    "else:\n",
    "      batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4888cfbb-d45c-4407-a549-12a565a91561",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_fname = '/content/models/mymodel/' + base_pipeline_file\n",
    "fine_tune_checkpoint = '/content/models/mymodel/' + model_name + '/checkpoint/ckpt-0'\n",
    "\n",
    "def get_num_classes(pbtxt_fname):\n",
    "    from object_detection.utils import label_map_util\n",
    "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
    "    categories = label_map_util.convert_label_map_to_categories(\n",
    "        label_map, max_num_classes=90, use_display_name=True)\n",
    "    category_index = label_map_util.create_category_index(categories)\n",
    "    return len(category_index.keys())\n",
    "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
    "print('Total classes:', num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a44f57c-7a70-42d6-92ff-7e91f39c41f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom configuration file by writing the dataset, model checkpoint, and training parameters into the base pipeline file\n",
    "import re\n",
    "\n",
    "%cd /content/models/mymodel\n",
    "print('writing custom configuration file')\n",
    "\n",
    "with open(pipeline_fname) as f:\n",
    "    s = f.read()\n",
    "with open('pipeline_file.config', 'w') as f:\n",
    "\n",
    "    # Set fine_tune_checkpoint path\n",
    "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
    "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
    "\n",
    "    # Set tfrecord files for train and test datasets\n",
    "    s = re.sub(\n",
    "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
    "    s = re.sub(\n",
    "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', 'input_path: \"{}\"'.format(val_record_fname), s)\n",
    "\n",
    "    # Set label_map_path\n",
    "    s = re.sub(\n",
    "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
    "\n",
    "    # Set batch_size\n",
    "    s = re.sub('batch_size: [0-9]+',\n",
    "               'batch_size: {}'.format(batch_size), s)\n",
    "\n",
    "    # Set training steps, num_steps\n",
    "    s = re.sub('num_steps: [0-9]+',\n",
    "               'num_steps: {}'.format(num_steps), s)\n",
    "\n",
    "    # Set number of classes num_classes\n",
    "    s = re.sub('num_classes: [0-9]+',\n",
    "               'num_classes: {}'.format(num_classes), s)\n",
    "\n",
    "    # Change fine-tune checkpoint type from \"classification\" to \"detection\"\n",
    "    s = re.sub(\n",
    "        'fine_tune_checkpoint_type: \"classification\"', 'fine_tune_checkpoint_type: \"{}\"'.format('detection'), s)\n",
    "\n",
    "    # If using ssd-mobilenet-v2, reduce learning rate (because it's too high in the default config file)\n",
    "    if chosen_model == 'ssd-mobilenet-v2':\n",
    "        s = re.sub('learning_rate_base: .8',\n",
    "                     'learning_rate_base: .08', s)\n",
    "\n",
    "        s = re.sub('warmup_learning_rate: 0.13333',\n",
    "                 'warmup_learning_rate: .026666', s)\n",
    "\n",
    "    # If using efficientdet-d0, use fixed_shape_resizer instead of keep_aspect_ratio_resizer (because it isn't supported by TFLite)\n",
    "    if chosen_model == 'efficientdet-d0':\n",
    "        s = re.sub('keep_aspect_ratio_resizer', 'fixed_shape_resizer', s)\n",
    "        s = re.sub('pad_to_max_dimension: true', '', s)\n",
    "        s = re.sub('min_dimension', 'height', s)\n",
    "        s = re.sub('max_dimension', 'width', s)\n",
    "\n",
    "    f.write(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec44c27e-1a8a-4a15-856c-625af5eabeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_file = '/content/models/mymodel/pipeline_file.config'\n",
    "model_dir = '/content/training/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2bf2c4-c62d-4efc-9dab-fef1123c1f12",
   "metadata": {},
   "source": [
    "### Trénovanie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc071d45-0187-429a-beb1-2ac9d0f97299",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python /content/models/research/object_detection/model_main_tf2.py \\\n",
    "    --pipeline_config_path={pipeline_file} \\\n",
    "    --model_dir={model_dir} \\\n",
    "    --alsologtostderr \\\n",
    "    --num_train_steps={num_steps} \\\n",
    "    --sample_1_of_n_eval_examples=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee50d3a-6618-4804-9de2-fe184b42bce3",
   "metadata": {},
   "source": [
    "### Uloženie natrénovaného modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9ce6ed-f33d-407c-b00a-2f38284f0c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a directory to store the trained TFLite model\n",
    "!mkdir /content/custom_model_lite\n",
    "output_directory = '/content/custom_model_lite'\n",
    "\n",
    "# Path to training directory (the conversion script automatically chooses the highest checkpoint file)\n",
    "last_model_path = '/content/training'\n",
    "\n",
    "!python /content/models/research/object_detection/export_tflite_graph_tf2.py \\\n",
    "    --trained_checkpoint_dir {last_model_path} \\\n",
    "    --output_directory {output_directory} \\\n",
    "    --pipeline_config_path {pipeline_file}\n",
    "\n",
    "# Convert exported graph file into TFLite model file\n",
    "import tensorflow as tf\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model('/content/custom_model_lite/saved_model')\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('/content/custom_model_lite/detect.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802c5f27-cf5f-4ecc-96de-55356c68ab10",
   "metadata": {},
   "source": [
    "### Načítanie modelu\n",
    "\n",
    "Nastavenie cesty ku modelu, testovým dátam, výstupnému súboru, počtu testových obrázkov a confidence threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c21bba-a2b5-47e2-97ba-ded833959b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_IMAGES='drive/MyDrive/dataset/test/'  \n",
    "PATH_TO_MODEL='detect.tflite'   \n",
    "PATH_TO_LABELS='labelmap.txt' \n",
    "SAVE_PATH = \"inferenced\"\n",
    "min_conf_threshold=0.35   \n",
    "images_to_test = 414   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ef637e-a053-4431-904f-da9efb8cb670",
   "metadata": {},
   "source": [
    "### Vizualizácia predikcií\n",
    "\n",
    "Vykonanie vizualizácie na všetky obrázky v testovacej množine a následné uloženie do súborov:\n",
    "\n",
    "*inferenced*:\n",
    ">TP - súbor pre obrázky s detegovanými objektmi\n",
    " \n",
    ">TN - súbor pre obrázky bez detegovaných objektov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2a2e89-643d-4243-b641-ccd72f8fed57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "import glob\n",
    "import random\n",
    "import importlib.util\n",
    "from tensorflow.lite.python.interpreter import Interpreter\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "### Define function for inferencing with TFLite model and displaying results\n",
    "\n",
    "def tflite_detect_images(modelpath, imgpath, lblpath, min_conf=0.5, num_test_images=10, savepath='/content/ssd_035'):\n",
    "\n",
    "    # Grab filenames of all images in test folder\n",
    "    images = glob.glob(imgpath + '/*.jpg') + glob.glob(imgpath + '/*.JPG') + glob.glob(imgpath + '/*.png') + glob.glob(imgpath + '/*.bmp')\n",
    "\n",
    "    # Create subfolders for TP and TN images\n",
    "    tp_folder = os.path.join(savepath, 'TP')\n",
    "    tn_folder = os.path.join(savepath, 'TN')\n",
    "    os.makedirs(tp_folder, exist_ok=True)\n",
    "    os.makedirs(tn_folder, exist_ok=True)\n",
    "\n",
    "    # Load the label map into memory\n",
    "    with open(lblpath, 'r') as f:\n",
    "        labels = [line.strip() for line in f.readlines()]\n",
    "\n",
    "    # Load the Tensorflow Lite model into memory\n",
    "    interpreter = Interpreter(model_path=modelpath)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    # Get model details\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    height = input_details[0]['shape'][1]\n",
    "    width = input_details[0]['shape'][2]\n",
    "\n",
    "    float_input = (input_details[0]['dtype'] == np.float32)\n",
    "\n",
    "    input_mean = 127.5\n",
    "    input_std = 127.5\n",
    "\n",
    "    # Randomly select test images\n",
    "    images_to_test = random.sample(images, num_test_images)\n",
    "\n",
    "    # Loop over every image and perform detection\n",
    "    for image_path in images_to_test:\n",
    "\n",
    "        # Load image and resize to expected shape [1xHxWx3]\n",
    "        image = cv2.imread(image_path)\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        imH, imW, _ = image.shape\n",
    "        image_resized = cv2.resize(image_rgb, (width, height))\n",
    "        input_data = np.expand_dims(image_resized, axis=0)\n",
    "\n",
    "        # Normalize pixel values if using a floating model (i.e. if model is non-quantized)\n",
    "        if float_input:\n",
    "            input_data = (np.float32(input_data) - input_mean) / input_std\n",
    "\n",
    "        # Perform the actual detection by running the model with the image as input\n",
    "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "        interpreter.invoke()\n",
    "\n",
    "        # Retrieve detection results\n",
    "        boxes = interpreter.get_tensor(output_details[1]['index'])[0]  # Bounding box coordinates of detected objects\n",
    "        classes = interpreter.get_tensor(output_details[3]['index'])[0]  # Class index of detected objects\n",
    "        scores = interpreter.get_tensor(output_details[0]['index'])[0]  # Confidence of detected objects\n",
    "\n",
    "        detections = []\n",
    "        detection_found = False\n",
    "\n",
    "        # Loop over all detections and draw detection box if confidence is above minimum threshold\n",
    "        for i in range(len(scores)):\n",
    "            if ((scores[i] > min_conf) and (scores[i] <= 1.0)):\n",
    "                detection_found = True\n",
    "\n",
    "                # Get bounding box coordinates and draw box\n",
    "                ymin = int(max(1, (boxes[i][0] * imH)))\n",
    "                xmin = int(max(1, (boxes[i][1] * imW)))\n",
    "                ymax = int(min(imH, (boxes[i][2] * imH)))\n",
    "                xmax = int(min(imW, (boxes[i][3] * imW)))\n",
    "\n",
    "                cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (10, 255, 0), 2)\n",
    "\n",
    "                # Draw label\n",
    "                object_name = labels[int(classes[i])]  # Look up object name from \"labels\" array using class index\n",
    "                label = '%s: %d%%' % (object_name, int(scores[i] * 100))  # Example: 'person: 72%'\n",
    "                labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)  # Get font size\n",
    "                label_ymin = max(ymin, labelSize[1] + 10)  # Make sure not to draw label too close to top of window\n",
    "                cv2.rectangle(image, (xmin, label_ymin - labelSize[1] - 10), (xmin + labelSize[0], label_ymin + baseLine - 10), (255, 255, 255), cv2.FILLED)  # Draw white box to put label text in\n",
    "                cv2.putText(image, label, (xmin, label_ymin - 7), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)  # Draw label text\n",
    "\n",
    "                detections.append([object_name, scores[i], xmin, ymin, xmax, ymax])\n",
    "\n",
    "        # Determine the subfolder based on detection status\n",
    "        if detection_found:\n",
    "            subfolder = tp_folder\n",
    "        else:\n",
    "            subfolder = tn_folder\n",
    "\n",
    "        # Save the image to the appropriate subfolder\n",
    "        inferred_image_path = os.path.join(subfolder, os.path.basename(image_path))\n",
    "        cv2.imwrite(inferred_image_path, cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab0266d-8926-4904-9eab-c211129dc400",
   "metadata": {},
   "source": [
    "### Spustenie detekcie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33de535d-5b7e-4b02-9c23-79fa0ce08891",
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_detect_images(PATH_TO_MODEL, PATH_TO_IMAGES, PATH_TO_LABELS, min_conf_threshold, images_to_test, SAVE_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
